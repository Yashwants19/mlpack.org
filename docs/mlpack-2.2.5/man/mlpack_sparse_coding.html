<html >
<head >

<meta name="keywords" content="mlpack, libmlpack, c++, armadillo, machine learning, data mining, classification, regression, tree-based methods, dual-tree algorithm">
<meta name="description" content="mlpack: a scalable c++ machine learning library">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title >mlpack: a scalable c++ machine learning library</title>
</head><link rel="stylesheet" href="../../../style.css" /></link><link rel="stylesheet" href="../../style-man.css" /></link><link href="http://fonts.googleapis.com/css?family=Maven+Pro:500" rel="stylesheet" type="text/css" /></link>



<body ><br /></br>


<div class="titlebar">
   <a href="http://www.mlpack.org"><img src="../../../mlpack.png"></a>
</div>
<center >
<div class="mlnavbar">
  <div class="navcontainer">
   <div class="mlnavitem" name="mlnavmain"><a href="../../../index.html">main</a></div>
   <div class="mlnavitem" name="mlnavabout"><a href="../../../about.html">about</a></div>
   <div class="mlnavitem" name="mlnavdoc"><a href="../../../docs.html">docs</a></div>
   <div class="mlnavitem" name="mlnavhelp"><a href="../../../help.html">get help</a></div>
   <div class="mlnavitem" name="mlnavbugs"><a href="https://github.com/mlpack/mlpack">github</a></div>
  </div>
</div>
</center>
<div class="separator"></div>
<center >
<div class="mainsection smallertext manpage">

<h1 align="center">mlpack_sparse_coding</h1>



<h2>NAME
<a name="NAME"></a>
</h2>



<p class="closemargin first"><font class="code">mlpack_sparse_coding</font>
- sparse coding</p>

<h2>SYNOPSIS
<a name="SYNOPSIS"></a>
</h2>



<p class="closemargin first"><font class="code">mlpack_sparse_coding</font>
[<font class="code">-h</font>] [<font class="code">-v</font>]</p>

<h2>DESCRIPTION
<a name="DESCRIPTION"></a>
</h2>


<p class="closemargin first">An
implementation of Sparse Coding with Dictionary Learning,
which achieves sparsity via an l1-norm regularizer on the
codes (LASSO) or an (l1+l2)<font class="code">-norm</font> regularizer on the
codes (the Elastic Net). Given a dense data matrix X with n
points and d dimensions, sparse coding seeks to find a dense
dictionary matrix D with k atoms in d dimensions, and a
sparse coding matrix Z with n points in k dimensions.</p>

<p class="closemargin first">The original
data matrix X can then be reconstructed as D * Z. Therefore,
this program finds a representation of each point in X as a
sparse linear combination of atoms in the dictionary D.</p>

<p class="closemargin first">The sparse
coding is found with an algorithm which alternates between a
dictionary step, which updates the dictionary D, and a
sparse coding step, which updates the sparse coding
matrix.</p>

<p class="closemargin first">Once a
dictionary D is found, the sparse coding model may be used
to encode other matrices, and saved for future usage.</p>

<p class="closemargin first">To run this
program, either an input matrix or an already-saved sparse
coding model must be specified. An input matrix may be
specified with the <font class="code">--training_file</font> (<font class="code">-t</font>)
option, along with the number of atoms in the dictionary
(<font class="code">--atoms</font>, or <font class="code">-k</font>). It is also possible to
specify an initial dictionary for the optimization, with the
<font class="code">--initial_dictionary</font> (<font class="code">-i</font>) option. An input
model may be specified with the <font class="code">--input_model_file</font>
(<font class="code">-m</font>) option. There are also other training options
available.</p>

<p class="closemargin first">As an example,
to build a sparse coding model on the dataset in data.csv
using 200 atoms and an l1-regularization parameter of 0.1,
saving the model into model.xml, use</p>

<p class="closemargin first">$ sparse_coding
<font class="code">-t</font> data.csv <font class="code">-k</font> 200 <font class="code">-l</font> 0.1 <font class="code">-M</font>
model.xml</p>

<p class="closemargin first">Then, this
model could be used to encode a new matrix, otherdata.csv,
and save the output codes to codes.csv:</p>

<p class="closemargin first">$ sparse_coding
<font class="code">-m</font> model.xml <font class="code">-T</font> otherdata.csv <font class="code">-c</font>
codes.csv</p>

<h2>OPTIONAL INPUT OPTIONS
<a name="OPTIONAL INPUT OPTIONS"></a>
</h2>


<p class="closemargin first"><font class="code">--atoms (-k)
[int]</font></p>

<p class="farmargin">Number of atoms in the
dictionary. Default value 0.</p>

<p class="closemargin"><font class="code">--help (-h)</font></p>

<p class="farmargin">Default help info.</p>

<p class="closemargin"><font class="code">--info [string]</font></p>

<p class="farmargin">Get help on a specific module
or option. Default value &rsquo;&rsquo;.
<font class="code">--initial_dictionary</font> (<font class="code">-i</font>) [string] Filename
for optional initial dictionary. Default value
&rsquo;&rsquo;. <font class="code">--input_model_file</font> (<font class="code">-m</font>)
[string] File containing input sparse coding model. Default
value &rsquo;&rsquo;.</p>

<p class="closemargin"><font class="code">--lambda1 (-l)
[double]</font></p>

<p class="farmargin">Sparse coding l1-norm
regularization parameter. Default value 0.</p>

<p class="closemargin"><font class="code">--lambda2 (-L)
[double]</font></p>

<p class="farmargin">Sparse coding l2-norm
regularization parameter. Default value 0.</p>

<p class="closemargin"><font class="code">--max_iterations (-n)
[int]</font></p>

<p class="farmargin">Maximum number of iterations
for sparse coding (0 indicates no limit). Default value 0.
<font class="code">--newton_tolerance</font> (<font class="code">-w</font>) [double] Tolerance for
convergence of Newton method. Default value 1e-06.</p>

<p class="closemargin"><font class="code">--normalize (-N)</font></p>

<p class="farmargin">If set, the input data matrix
will be normalized before coding.
<font class="code">--objective_tolerance</font> (<font class="code">-o</font>) [double] Tolerance
for convergence of the objective function. Default value
0.01.</p>

<p class="closemargin"><font class="code">--seed (-s) [int]</font></p>

<p class="farmargin">Random seed. If 0,
&rsquo;std::time(NULL)&rsquo; is used. Default value 0.
<font class="code">--training_file</font> (<font class="code">-t</font>) [string] Filename of the
training data (X). Default value &rsquo;&rsquo;.</p>

<p class="closemargin"><font class="code">--verbose (-v)</font></p>

<p class="farmargin">Display informational messages
and the full list of parameters and timers at the end of
execution.</p>

<p class="closemargin"><font class="code">--version (-V)</font></p>

<p class="farmargin">Display the version of
mlpack.</p>

<h2>OPTIONAL OUTPUT OPTIONS
<a name="OPTIONAL OUTPUT OPTIONS"></a>
</h2>



<p class="closemargin first"><font class="code">--codes_file
(-c) [string]</font></p>

<p class="farmargin">Filename to save the output
sparse codes to. Default value &rsquo;&rsquo;.
<font class="code">--dictionary_file</font> (<font class="code">-d</font>) [string] Filename to
save the output dictionary to. Default value &rsquo;&rsquo;.
<font class="code">--output_model_file</font> (<font class="code">-M</font>) [string] File to save
trained sparse coding model to. Default value
&rsquo;&rsquo;.</p>

<p class="closemargin"><font class="code">--test_file (-T)
[string]</font></p>

<p class="farmargin">File containing data matrix to
be encoded by trained model. Default value
&rsquo;&rsquo;.</p>

<h2>ADDITIONAL INFORMATION
<a name="ADDITIONAL INFORMATION"></a>
</h2>


<h2>ADDITIONAL INFORMATION
<a name="ADDITIONAL INFORMATION"></a>
</h2>


<p class="closemargin first">For further
information, including relevant papers, citations, and
theory, For further information, including relevant papers,
citations, and theory, consult the documentation found at
http://www.mlpack.org or included with your consult the
documentation found at http://www.mlpack.org or included
with your DISTRIBUTION OF MLPACK. DISTRIBUTION OF
MLPACK.</p>
</div></body></html>
