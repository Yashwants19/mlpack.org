.\" Text automatically generated by txt2man
.TH mlpack_gmm_train  "1" "" ""
.SH NAME
\fBmlpack_gmm_train \fP- gaussian mixture model (gmm) training
.SH SYNOPSIS
.nf
.fam C
 \fBmlpack_gmm_train\fP [\fB-h\fP] [\fB-v\fP]  
.fam T
.fi
.fam T
.fi
.SH DESCRIPTION


This program takes a parametric estimate of a Gaussian mixture model (GMM)
using the EM algorithm to find the maximum likelihood estimate. The model may
be saved and reused by other mlpack GMM tools.
.PP
The input data to train on must be specified with the '\fB--input_file\fP (\fB-i\fP)'
parameter, and the number of Gaussians in the model must be specified with the
\(cq\fB--gaussians\fP (\fB-g\fP)' parameter. Optionally, many trials with different random
initializations may be run, and the result with highest log-likelihood on the
training data will be taken. The number of trials to run is specified with
the '\fB--trials\fP (\fB-t\fP)' parameter. By default, only one trial is run.
.PP
The tolerance for convergence and maximum number of iterations of the EM
algorithm are specified with the '\fB--tolerance\fP (\fB-T\fP)' and '\fB--max_iterations\fP
(\fB-n\fP)' parameters, respectively. The GMM may be initialized for training with
another model, specified with the '\fB--input_model_file\fP (\fB-m\fP)' parameter.
Otherwise, the model is initialized by running k-means on the data. The
k-means clustering initialization can be controlled with the '\fB--refined_start\fP
(\fB-r\fP)', '\fB--samplings\fP (\fB-S\fP)', and '\fB--percentage\fP (\fB-p\fP)' parameters. If
\(cq\fB--refined_start\fP (\fB-r\fP)' is specified, then the Bradley-Fayyad refined start
initialization will be used. This can often lead to better clustering
results.
.PP
If GMM training fails with an error indicating that a covariance matrix could
not be inverted, make sure that the '\fB--no_force_positive\fP (\fB-P\fP)' parameter is
not specified. Alternately, adding a small amount of Gaussian noise (using
the '\fB--noise\fP (\fB-N\fP)' parameter) to the entire dataset may help prevent Gaussians
with zero variance in a particular dimension, which is usually the cause of
non-invertible covariance matrices.
.PP
The '\fB--no_force_positive\fP (\fB-P\fP)' parameter, if set, will avoid the checks after
each iteration of the EM algorithm which ensure that the covariance matrices
are positive definite. Specifying the flag can cause faster runtime, but may
also cause non-positive definite covariance matrices, which will cause the
program to crash.
.PP
As an example, to train a 6-Gaussian GMM on the data in 'data.csv' with a
maximum of 100 iterations of EM and 3 trials, saving the trained GMM to
\(cqgmm.bin', the following command can be used:
.PP
$ gmm_train \fB--input_file\fP data.csv \fB--gaussians\fP 6 \fB--trials\fP 3 \fB--output_model_file\fP
gmm.bin
.PP
To re-train that GMM on another set of data 'data2.csv', the following command
may be used: 
.PP
$ gmm_train \fB--input_model_file\fP gmm.bin \fB--input_file\fP data2.csv \fB--gaussians\fP 6
\fB--output_model_file\fP new_gmm.bin
.SH REQUIRED INPUT OPTIONS 

.TP
.B
\fB--gaussians\fP (\fB-g\fP) [int]
Number of Gaussians in the GMM.
.TP
.B
\fB--input_file\fP (\fB-i\fP) [string]
The training data on which the model will be
fit.
.SH OPTIONAL INPUT OPTIONS 

.TP
.B
\fB--help\fP (\fB-h\fP) [bool]
Default help info.
.TP
.B
\fB--info\fP [string]
Get help on a specific module or option. 
Default value ''.
\fB--input_model_file\fP (\fB-m\fP) [string] 
Initial input GMM model to start training with. 
Default value ''.
.TP
.B
\fB--max_iterations\fP (\fB-n\fP) [int]
Maximum number of iterations of EM algorithm
(passing 0 will run until convergence). Default
value 250.
\fB--no_force_positive\fP (\fB-P\fP) [bool] 
Do not force the covariance matrices to be
positive definite.
.TP
.B
\fB--noise\fP (\fB-N\fP) [double]
Variance of zero-mean Gaussian noise to add to
data. Default value 0.
.TP
.B
\fB--percentage\fP (\fB-p\fP) [double]
If using \fB--refined_start\fP, specify the percentage
of the dataset used for each sampling (should be
between 0.0 and 1.0). Default value 0.02.
.TP
.B
\fB--refined_start\fP (\fB-r\fP) [bool]
During the initialization, use refined initial
positions for k-means clustering (Bradley and
Fayyad, 1998).
.TP
.B
\fB--samplings\fP (\fB-S\fP) [int]
If using \fB--refined_start\fP, specify the number of
samplings used for initial points. Default
value 100.
.TP
.B
\fB--seed\fP (\fB-s\fP) [int]
Random seed. If 0, 'std::time(NULL)' is used. 
Default value 0.
.TP
.B
\fB--tolerance\fP (\fB-T\fP) [double]
Tolerance for convergence of EM. Default value
1e-10.
.TP
.B
\fB--trials\fP (\fB-t\fP) [int]
Number of trials to perform in training GMM. 
Default value 1.
.TP
.B
\fB--verbose\fP (\fB-v\fP) [bool]
Display informational messages and the full list
of parameters and timers at the end of
execution.
.TP
.B
\fB--version\fP (\fB-V\fP) [bool]
Display the version of mlpack.
.SH OPTIONAL OUTPUT OPTIONS 

\fB--output_model_file\fP (\fB-M\fP) [string] 
Output for trained GMM model. Default value
\(cq'.
.SH ADDITIONAL INFORMATION
.SH ADDITIONAL INFORMATION


For further information, including relevant papers, citations, and theory,
For further information, including relevant papers, citations, and theory,
consult the documentation found at http://www.mlpack.org or included with your
consult the documentation found at http://www.mlpack.org or included with your
DISTRIBUTION OF MLPACK.
DISTRIBUTION OF MLPACK.
