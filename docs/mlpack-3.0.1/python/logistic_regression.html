<html >
<head >

<meta name="keywords" content="mlpack, libmlpack, c++, armadillo, machine learning, data mining, classification, regression, tree-based methods, dual-tree algorithm">
<meta name="description" content="mlpack: a fast, flexible c++ machine learning library">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title >mlpack: a fast, flexible c++ machine learning library</title>
</head><link rel="stylesheet" href="../../../style.css" /></link><link rel="stylesheet" href="../../style-python.css" /></link><link href="http://fonts.googleapis.com/css?family=Maven+Pro:500" rel="stylesheet" type="text/css" /></link>



<body ><br /></br>


<div class="titlebar">
   <a href="http://www.mlpack.org"><img src="../../../mlpack.png"></a>
</div>
<center >
<div class="mlnavbar">
  <div class="navcontainer">
   <div class="mlnavitem" name="mlnavmain"><a href="../../../index.html">main</a></div>
   <div class="mlnavitem" name="mlnavabout"><a href="../../../about.html">about</a></div>
   <div class="mlnavitem" name="mlnavdoc"><a href="../../../docs.html">docs</a></div>
   <div class="mlnavitem" name="mlnavhelp"><a href="../../../help.html">get help</a></div>
   <div class="mlnavitem" name="mlnavbugs"><a href="https://github.com/mlpack/mlpack">github</a></div>
  </div>
</div>
</center>
<div class="separator"></div>
<center >
<div class="mainsection smallertext pythonpage">
<h1><center>mlpack.logistic_regression</center></h1>
<font class="titlecode">logistic_regression(...)</font><br />
<font class="titlebold">L2-regularized Logistic Regression and Prediction</font>
<p class="importcode">&gt;&gt;&gt; from mlpack import logistic_regression</p><p>An implementation of L2-regularized logistic regression using either the L-BFGS optimizer or SGD (stochastic gradient descent).  This solves the regression problem</p>
</p>
<p>  y = (1 / 1 + e^-(X * b))</p>
</p>
<p>where y takes values 0 or 1.</p>
</p>
<p>This program allows loading a logistic regression model (via the <font class="code">'input_model'</font> parameter) or training a logistic regression model given training data (specified with the <font class="code">'training'</font> parameter), or both those things at once.  In addition, this program allows classification on a test dataset (specified with the <font class="code">'test'</font> parameter) and the classification results may be saved with the <font class="code">'output'</font> output parameter.  The trained logistic regression model may be saved using the <font class="code">'output_model'</font> output parameter.</p>
</p>
<p>The training data, if specified, may have class labels as its last dimension.  Alternately, the <font class="code">'labels'</font> parameter may be used to specify a separate matrix of labels.</p>
</p>
<p>When a model is being trained, there are many options.  L2 regularization (to prevent overfitting) can be specified with the <font class="code">'lambda_'</font> option, and the optimizer used to train the model can be specified with the <font class="code">'optimizer'</font> parameter.  Available options are <font class="code">'sgd'</font> (stochastic gradient descent) and <font class="code">'lbfgs'</font> (the L-BFGS optimizer).  There are also various parameters for the optimizer; the <font class="code">'max_iterations'</font> parameter specifies the maximum number of allowed iterations, and the <font class="code">'tolerance'</font> parameter specifies the tolerance for  convergence.  For the SGD optimizer, the <font class="code">'step_size'</font> parameter controls the step size taken at each iteration by the optimizer.  The batch size for SGD is controlled with the <font class="code">'batch_size'</font> parameter. If the objective function for your data is oscillating between Inf and 0, the step size is probably too large.  There are more parameters for the optimizers, but the C++ interface must be used to access these.</p>
</p>
<p>For SGD, an iteration refers to a single point. So to take a single pass over the dataset with SGD, <font class="code">'max_iterations'</font> should be set to the number of points in the dataset.</p>
</p>
<p>Optionally, the model can be used to predict the responses for another matrix of data points, if <font class="code">'test'</font> is specified.  The <font class="code">'test'</font> parameter can be specified without the <font class="code">'training'</font> parameter, so long as an existing logistic regression model is given with the <font class="code">'input_model'</font> parameter.  The output predictions from the logistic regression model may be saved with the <font class="code">'output'</font> parameter.</p>
</p>
<p>This implementation of logistic regression does not support the general multi-class case but instead only the two-class case.  Any labels must be either 0 or 1.  For more classes, see the softmax_regression program.</p>
</p>
<p>As an example, to train a logistic regression model on the data <font class="code">''</font>data'</font>'</font> with labels <font class="code">''</font>labels'</font>'</font> with L2 regularization of 0.1, saving the model to <font class="code">''</font>lr_model'</font>'</font>, the following command may be used:</p>
</p>
<p class="codeblock"><font class="code">&gt;&gt;&gt; logistic_regression(training=data, labels=labels, lambda_=0.1)<br />
&gt;&gt;&gt; lr_model = output['output_model']</font></p>
</p>
<p>Then, to use that model to predict classes for the dataset <font class="code">''</font>test'</font>'</font>, storing the output predictions in <font class="code">''</font>predictions'</font>'</font>, the following command may be used: </p>
</p>
<p class="codeblock"><font class="code">&gt;&gt;&gt; logistic_regression(input_model=lr_model, test=test)<br />
&gt;&gt;&gt; predictions = output['output']</font></p><h2>input options</h2>
<ul>
<li><font class="code">batch_size</font> <font class="codetype">(int)</font>: Batch size for SGD.  Default value 64.</li><li><font class="code">copy_all_inputs</font> <font class="codetype">(bool)</font>: If specified, all input parameters will be deep copied before the method is run.  This is useful for debugging problems where the input parameters are being modified by the algorithm, but can slow down the code.</li><li><font class="code">decision_boundary</font> <font class="codetype">(float)</font>: Decision boundary for prediction; if the logistic function for a point is less than the boundary, the class is taken to be 0; otherwise, the class is 1.  Default value 0.5.</li><li><font class="code">input_model</font> <font class="codetype">(mlpack.LogisticRegressionType)</font>: Existing model (parameters).</li><li><font class="code">labels</font> <font class="codetype">(numpy vector or array, int/long dtype)</font>: A matrix containing labels (0 or 1) for the points in the training set (y).</li><li><font class="code">lambda_</font> <font class="codetype">(float)</font>: L2-regularization parameter for training.  Default value 0.</li><li><font class="code">max_iterations</font> <font class="codetype">(int)</font>: Maximum iterations for optimizer (0 indicates no limit).  Default value 10000.</li><li><font class="code">optimizer</font> <font class="codetype">(string)</font>: Optimizer to use for training ('lbfgs' or 'sgd').  Default value lbfgs.</li><li><font class="code">step_size</font> <font class="codetype">(float)</font>: Step size for SGD optimizer.  Default value 0.01.</li><li><font class="code">test</font> <font class="codetype">(numpy matrix or arraylike, float dtype)</font>: Matrix containing test dataset.</li><li><font class="code">tolerance</font> <font class="codetype">(float)</font>: Convergence tolerance for optimizer.  Default value 1e-10.</li><li><font class="code">training</font> <font class="codetype">(numpy matrix or arraylike, float dtype)</font>: A matrix containing the training set (the matrix of predictors, X).</li><li><font class="code">verbose</font> <font class="codetype">(bool)</font>: Display informational messages and the full list of parameters and timers at the end of execution.</li></ul>
<h2>output options</h2>
<p>The return value from the binding is a dict containing the following elements:</p>
<ul><li><font class="code">output</font> <font class="codetype">(numpy vector, int dtype)</font>: If test data is specified, this matrix is where the predictions for the test set will be saved.</li><li><font class="code">output_model</font> <font class="codetype">(mlpack.LogisticRegressionType)</font>: Output for trained logistic regression model.</li><li><font class="code">output_probabilities</font> <font class="codetype">(numpy matrix, float dtype)</font>: If test data is specified, this matrix is where the class probabilities for the test set will be saved.</li><ul>
</ul>
</div>
</body>
</html>
