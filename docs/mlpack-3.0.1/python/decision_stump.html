<html >
<head >

<meta name="keywords" content="mlpack, libmlpack, c++, armadillo, machine learning, data mining, classification, regression, tree-based methods, dual-tree algorithm">
<meta name="description" content="mlpack: a fast, flexible c++ machine learning library">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title >mlpack: a fast, flexible c++ machine learning library</title>
</head><link rel="stylesheet" href="../../../style.css" /></link><link rel="stylesheet" href="../../style-python.css" /></link><link href="http://fonts.googleapis.com/css?family=Maven+Pro:500" rel="stylesheet" type="text/css" /></link>



<body ><br /></br>


<div class="titlebar">
   <a href="http://www.mlpack.org"><img src="../../../mlpack.png"></a>
</div>
<center >
<div class="mlnavbar">
  <div class="navcontainer">
   <div class="mlnavitem" name="mlnavmain"><a href="../../../index.html">main</a></div>
   <div class="mlnavitem" name="mlnavabout"><a href="../../../about.html">about</a></div>
   <div class="mlnavitem" name="mlnavdoc"><a href="../../../docs.html">docs</a></div>
   <div class="mlnavitem" name="mlnavhelp"><a href="../../../help.html">get help</a></div>
   <div class="mlnavitem" name="mlnavbugs"><a href="https://github.com/mlpack/mlpack">github</a></div>
  </div>
</div>
</center>
<div class="separator"></div>
<center >
<div class="mainsection smallertext pythonpage">
<h1><center>mlpack.decision_stump</center></h1>
<font class="titlecode">decision_stump(...)</font><br />
<font class="titlebold">Decision Stump</font>
<p class="importcode">&gt;&gt;&gt; from mlpack import decision_stump</p><p>This program implements a decision stump, which is a single-level decision tree.  The decision stump will split on one dimension of the input data, and will split into multiple buckets.  The dimension and bins are selected by maximizing the information gain of the split.  Optionally, the minimum number of training points in each bin can be specified with the <font class="code">'bucket_size'</font> parameter.</p>
</p>
<p>The decision stump is parameterized by a splitting dimension and a vector of values that denote the splitting values of each bin.</p>
</p>
<p>This program enables several applications: a decision tree may be trained or loaded, and then that decision tree may be used to classify a given set of test points.  The decision tree may also be saved to a file for later usage.</p>
</p>
<p>To train a decision stump, training data should be passed with the <font class="code">'training'</font> parameter, and their corresponding labels should be passed with the <font class="code">'labels'</font> option.  Optionally, if <font class="code">'labels'</font> is not specified, the labels are assumed to be the last dimension of the training dataset.  The <font class="code">'bucket_size'</font> parameter controls the minimum number of training points in each decision stump bucket.</p>
</p>
<p>For classifying a test set, a decision stump may be loaded with the <font class="code">'input_model'</font> parameter (useful for the situation where a stump has already been trained), and a test set may be specified with the <font class="code">'test'</font> parameter.  The predicted labels can be saved with the <font class="code">'predictions'</font> output parameter.</p>
</p>
<p>Because decision stumps are trained in batch, retraining does not make sense and thus it is not possible to pass both <font class="code">'training'</font> and <font class="code">'input_model'</font>; instead, simply build a new decision stump with the training data.</p>
</p>
<p>After training, a decision stump can be saved with the <font class="code">'output_model'</font> output parameter.  That stump may later be re-used in subsequent calls to this program (or others).</p><h2>input options</h2>
<ul>
<li><font class="code">bucket_size</font> <font class="codetype">(int)</font>: The minimum number of training points in each decision stump bucket.  Default value 6.</li><li><font class="code">copy_all_inputs</font> <font class="codetype">(bool)</font>: If specified, all input parameters will be deep copied before the method is run.  This is useful for debugging problems where the input parameters are being modified by the algorithm, but can slow down the code.</li><li><font class="code">input_model</font> <font class="codetype">(mlpack.DSModelType)</font>: Decision stump model to load.</li><li><font class="code">labels</font> <font class="codetype">(numpy vector or array, int/long dtype)</font>: Labels for the training set. If not specified, the labels are assumed to be the last row of the training data.</li><li><font class="code">test</font> <font class="codetype">(numpy matrix or arraylike, float dtype)</font>: A dataset to calculate predictions for.</li><li><font class="code">training</font> <font class="codetype">(numpy matrix or arraylike, float dtype)</font>: The dataset to train on.</li><li><font class="code">verbose</font> <font class="codetype">(bool)</font>: Display informational messages and the full list of parameters and timers at the end of execution.</li></ul>
<h2>output options</h2>
<p>The return value from the binding is a dict containing the following elements:</p>
<ul><li><font class="code">output_model</font> <font class="codetype">(mlpack.DSModelType)</font>: Output decision stump model to save.</li><li><font class="code">predictions</font> <font class="codetype">(numpy vector, int dtype)</font>: The output matrix that will hold the predicted labels for the test set.</li><ul>
</ul>
</div>
</body>
</html>
