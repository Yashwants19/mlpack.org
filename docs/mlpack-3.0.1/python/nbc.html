<html >
<head >

<meta name="keywords" content="mlpack, libmlpack, c++, armadillo, machine learning, data mining, classification, regression, tree-based methods, dual-tree algorithm">
<meta name="description" content="mlpack: a fast, flexible c++ machine learning library">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title >mlpack: a fast, flexible c++ machine learning library</title>
</head><link rel="stylesheet" href="../../../style.css" /></link><link rel="stylesheet" href="../../style-python.css" /></link><link href="http://fonts.googleapis.com/css?family=Maven+Pro:500" rel="stylesheet" type="text/css" /></link>



<body ><br /></br>


<div class="titlebar">
   <a href="http://www.mlpack.org"><img src="../../../mlpack.png"></a>
</div>
<center >
<div class="mlnavbar">
  <div class="navcontainer">
   <div class="mlnavitem" name="mlnavmain"><a href="../../../index.html">main</a></div>
   <div class="mlnavitem" name="mlnavabout"><a href="../../../about.html">about</a></div>
   <div class="mlnavitem" name="mlnavdoc"><a href="../../../docs.html">docs</a></div>
   <div class="mlnavitem" name="mlnavhelp"><a href="../../../help.html">get help</a></div>
   <div class="mlnavitem" name="mlnavbugs"><a href="https://github.com/mlpack/mlpack">github</a></div>
  </div>
</div>
</center>
<div class="separator"></div>
<center >
<div class="mainsection smallertext pythonpage">
<h1><center>mlpack.nbc</center></h1>
<font class="titlecode">nbc(...)</font><br />
<font class="titlebold">Parametric Naive Bayes Classifier</font>
<p class="importcode">&gt;&gt;&gt; from mlpack import nbc</p><p>This program trains the Naive Bayes classifier on the given labeled training set, or loads a model from the given model file, and then may use that trained model to classify the points in a given test set.</p>
</p>
<p>The training set is specified with the <font class="code">'training'</font> parameter.  Labels may be either the last row of the training set, or alternately the <font class="code">'labels'</font> parameter may be specified to pass a separate matrix of labels.</p>
</p>
<p>If training is not desired, a pre-existing model may be loaded with the <font class="code">'input_model'</font> parameter.</p>
</p>
</p>
</p>
<p>The <font class="code">'incremental_variance'</font> parameter can be used to force the training to use an incremental algorithm for calculating variance.  This is slower, but can help avoid loss of precision in some cases.</p>
</p>
<p>If classifying a test set is desired, the test set may be specified with the <font class="code">'test'</font> parameter, and the classifications may be saved with the <font class="code">'output'</font> output parameter.  If saving the trained model is desired, this may be done with the <font class="code">'output_model'</font> output parameter.</p>
</p>
<p>For example, to train a Naive Bayes classifier on the dataset <font class="code">'data'</font> with labels <font class="code">'labels'</font> and save the model to <font class="code">'nbc_model'</font>, the following command may be used:</p>
</p>
<p class="codeblock"><font class="code">&gt;&gt;&gt; nbc(training=data, labels=labels)<br />
&gt;&gt;&gt; nbc_model = output['output_model']</font></p>
</p>
<p>Then, to use <font class="code">'nbc_model'</font> to predict the classes of the dataset <font class="code">'test_set'</font> and save the predicted classes to <font class="code">'predictions'</font>, the following command may be used:</p>
</p>
<p class="codeblock"><font class="code">&gt;&gt;&gt; nbc(input_model=nbc_model, test=test_set)<br />
&gt;&gt;&gt; predictions = output['output']</font></p><h2>input options</h2>
<ul>
<li><font class="code">copy_all_inputs</font> <font class="codetype">(bool)</font>: If specified, all input parameters will be deep copied before the method is run.  This is useful for debugging problems where the input parameters are being modified by the algorithm, but can slow down the code.</li><li><font class="code">incremental_variance</font> <font class="codetype">(bool)</font>: The variance of each class will be calculated incrementally.</li><li><font class="code">input_model</font> <font class="codetype">(mlpack.NBCModelType)</font>: Input Naive Bayes model.</li><li><font class="code">labels</font> <font class="codetype">(numpy vector or array, int/long dtype)</font>: A file containing labels for the training set.</li><li><font class="code">test</font> <font class="codetype">(numpy matrix or arraylike, float dtype)</font>: A matrix containing the test set.</li><li><font class="code">training</font> <font class="codetype">(numpy matrix or arraylike, float dtype)</font>: A matrix containing the training set.</li><li><font class="code">verbose</font> <font class="codetype">(bool)</font>: Display informational messages and the full list of parameters and timers at the end of execution.</li></ul>
<h2>output options</h2>
<p>The return value from the binding is a dict containing the following elements:</p>
<ul><li><font class="code">output</font> <font class="codetype">(numpy vector, int dtype)</font>: The matrix in which the predicted labels for the test set will be written.</li><li><font class="code">output_model</font> <font class="codetype">(mlpack.NBCModelType)</font>: File to save trained Naive Bayes model to.</li><li><font class="code">output_probs</font> <font class="codetype">(numpy matrix, float dtype)</font>: The matrix in which the predicted probability of labels for the test set will be written.</li><ul>
</ul>
</div>
</body>
</html>
