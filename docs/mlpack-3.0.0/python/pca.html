<html >
<head >

<meta name="keywords" content="mlpack, libmlpack, c++, armadillo, machine learning, data mining, classification, regression, tree-based methods, dual-tree algorithm">
<meta name="description" content="mlpack: a scalable c++ machine learning library">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title >mlpack: a scalable c++ machine learning library</title>
</head><link rel="stylesheet" href="../../../style.css" /></link><link rel="stylesheet" href="../../style-python.css" /></link><link href="http://fonts.googleapis.com/css?family=Maven+Pro:500" rel="stylesheet" type="text/css" /></link>



<body ><br /></br>


<div class="titlebar">
   <a href="http://www.mlpack.org"><img src="../../../mlpack.png"></a>
</div>
<center >
<div class="mlnavbar">
  <div class="navcontainer">
   <div class="mlnavitem" name="mlnavmain"><a href="../../../index.html">main</a></div>
   <div class="mlnavitem" name="mlnavabout"><a href="../../../about.html">about</a></div>
   <div class="mlnavitem" name="mlnavdoc"><a href="../../../docs.html">docs</a></div>
   <div class="mlnavitem" name="mlnavhelp"><a href="../../../help.html">get help</a></div>
   <div class="mlnavitem" name="mlnavbugs"><a href="https://github.com/mlpack/mlpack">github</a></div>
  </div>
</div>
</center>
<div class="separator"></div>
<center >
<div class="mainsection smallertext pythonpage">
<h1><center>mlpack.pca</center></h1>
<font class="titlecode">pca(...)</font><br />
<font class="titlebold">Principal Components Analysis</font>
<p class="importcode">&gt;&gt;&gt; from mlpack import pca</p><p>This program performs principal components analysis on the given dataset using the exact, randomized, randomized block Krylov, or QUIC SVD method. It will transform the data onto its principal components, optionally performing dimensionality reduction by ignoring the principal components with the smallest eigenvalues.</p>
</p>
<p>Use the <font class="code">'input'</font> parameter to specify the dataset to perform PCA on.  A desired new dimensionality can be specified with the <font class="code">'new_dimensionality'</font> parameter, or the desired variance to retain can be specified with the <font class="code">'var_to_retain'</font> parameter.  If desired, the dataset can be scaled before running PCA with the <font class="code">'scale'</font> parameter.</p>
</p>
<p>Multiple different decomposition techniques can be used.  The method to use can be specified with the <font class="code">'decomposition_method'</font> parameter, and it may take the values <font class="code">'exact'</font>, <font class="code">'randomized'</font>, or <font class="code">'quic'</font>.</p>
</p>
<p>For example, to reduce the dimensionality of the matrix <font class="code">'data'</font> to 5 dimensions using randomized SVD for the decomposition, storing the output matrix to <font class="code">'data_mod'</font>, the following command can be used:</p>
</p>
<p class="codeblock"><font class="code">&gt;&gt;&gt; pca(input=data, new_dimensionality=5, decomposition_method='randomized')<br />
&gt;&gt;&gt; data_mod = output['output']</font></p><h2>input options</h2>
<ul>
<li><font class="code">input</font> <font class="codetype">(numpy matrix or arraylike, float dtype)</font>: <font class="required">[required]</font> Input dataset to perform PCA on.</li><li><font class="code">copy_all_inputs</font> <font class="codetype">(bool)</font>: If specified, all input parameters will be deep copied before the method is run.  This is useful for debugging problems where the input parameters are being modified by the algorithm, but can slow down the code.</li><li><font class="code">decomposition_method</font> <font class="codetype">(string)</font>: Method used for the principal components analysis: 'exact', 'randomized', 'randomized-block-krylov', 'quic'.  Default value exact.</li><li><font class="code">new_dimensionality</font> <font class="codetype">(int)</font>: Desired dimensionality of output dataset. If 0, no dimensionality reduction is performed.  Default value 0.</li><li><font class="code">scale</font> <font class="codetype">(bool)</font>: If set, the data will be scaled before running PCA, such that the variance of each feature is 1.</li><li><font class="code">var_to_retain</font> <font class="codetype">(float)</font>: Amount of variance to retain; should be between 0 and 1.  If 1, all variance is retained.  Overrides -d.  Default value 0.</li><li><font class="code">verbose</font> <font class="codetype">(bool)</font>: Display informational messages and the full list of parameters and timers at the end of execution.</li></ul>
<h2>output options</h2>
<p>The return value from the binding is a dict containing the following elements:</p>
<ul><li><font class="code">output</font> <font class="codetype">(numpy matrix, float dtype)</font>: Matrix to save modified dataset to.</li><ul>
</ul>
</div>
</body>
</html>
