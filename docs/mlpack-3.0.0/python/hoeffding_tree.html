<html >
<head >

<meta name="keywords" content="mlpack, libmlpack, c++, armadillo, machine learning, data mining, classification, regression, tree-based methods, dual-tree algorithm">
<meta name="description" content="mlpack: a scalable c++ machine learning library">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title >mlpack: a scalable c++ machine learning library</title>
</head><link rel="stylesheet" href="../../../style.css" /></link><link rel="stylesheet" href="../../style-python.css" /></link><link href="http://fonts.googleapis.com/css?family=Maven+Pro:500" rel="stylesheet" type="text/css" /></link>



<body ><br /></br>


<div class="titlebar">
   <a href="http://www.mlpack.org"><img src="../../../mlpack.png"></a>
</div>
<center >
<div class="mlnavbar">
  <div class="navcontainer">
   <div class="mlnavitem" name="mlnavmain"><a href="../../../index.html">main</a></div>
   <div class="mlnavitem" name="mlnavabout"><a href="../../../about.html">about</a></div>
   <div class="mlnavitem" name="mlnavdoc"><a href="../../../docs.html">docs</a></div>
   <div class="mlnavitem" name="mlnavhelp"><a href="../../../help.html">get help</a></div>
   <div class="mlnavitem" name="mlnavbugs"><a href="https://github.com/mlpack/mlpack">github</a></div>
  </div>
</div>
</center>
<div class="separator"></div>
<center >
<div class="mainsection smallertext pythonpage">
<h1><center>mlpack.hoeffding_tree</center></h1>
<font class="titlecode">hoeffding_tree(...)</font><br />
<font class="titlebold">Hoeffding trees</font>
<p class="importcode">&gt;&gt;&gt; from mlpack import hoeffding_tree</p><p>This program implements Hoeffding trees, a form of streaming decision tree suited best for large (or streaming) datasets.  This program supports both categorical and numeric data.  Given an input dataset, this program is able to train the tree with numerous training options, and save the model to a file.  The program is also able to use a trained model or a model from file in order to predict classes for a given test set.</p>
</p>
<p>The training file and associated labels are specified with the <font class="code">'training'</font> and <font class="code">'labels'</font> parameters, respectively. Optionally, if <font class="code">'labels'</font> is not specified, the labels are assumed to be the last dimension of the training dataset.</p>
</p>
<p>The training may be performed in batch mode (like a typical decision tree algorithm) by specifying the <font class="code">'batch_mode'</font> option, but this may not be the best option for large datasets.</p>
</p>
<p>When a model is trained, it may be saved via the <font class="code">'output_model'</font> output parameter.  A model may be loaded from file for further training or testing with the <font class="code">'input_model'</font> parameter.</p>
</p>
<p>Test data may be specified with the <font class="code">'test'</font> parameter, and if performance statistics are desired for that test set, labels may be specified with the <font class="code">'test_labels'</font> parameter.  Predictions for each test point may be saved with the <font class="code">'predictions'</font> output parameter, and class probabilities for each prediction may be saved with the <font class="code">'probabilities'</font> output parameter.</p>
</p>
<p>For example, to train a Hoeffding tree with confidence 0.99 with data <font class="code">'dataset'</font>, saving the trained tree to <font class="code">'tree'</font>, the following command may be used:</p>
</p>
<p class="codeblock"><font class="code">&gt;&gt;&gt; hoeffding_tree(training=dataset, confidence=0.99)<br />
&gt;&gt;&gt; tree = output['output_model']</font></p>
</p>
<p>Then, this tree may be used to make predictions on the test set <font class="code">'test_set'</font>, saving the predictions into <font class="code">'predictions'</font> and the class probabilities into <font class="code">'class_probs'</font> with the following command: </p>
</p>
<p class="codeblock"><font class="code">&gt;&gt;&gt; hoeffding_tree(input_model=tree, test=test_set)<br />
&gt;&gt;&gt; predictions = output['predictions']<br />
&gt;&gt;&gt; class_probs = output['probabilities']</font></p><h2>input options</h2>
<ul>
<li><font class="code">batch_mode</font> <font class="codetype">(bool)</font>: If true, samples will be considered in batch instead of as a stream.  This generally results in better trees but at the cost of memory usage and runtime.</li><li><font class="code">bins</font> <font class="codetype">(int)</font>: If the 'domingos' split strategy is used, this specifies the number of bins for each numeric split.  Default value 10.</li><li><font class="code">confidence</font> <font class="codetype">(float)</font>: Confidence before splitting (between 0 and 1).  Default value 0.95.</li><li><font class="code">copy_all_inputs</font> <font class="codetype">(bool)</font>: If specified, all input parameters will be deep copied before the method is run.  This is useful for debugging problems where the input parameters are being modified by the algorithm, but can slow down the code.</li><li><font class="code">info_gain</font> <font class="codetype">(bool)</font>: If set, information gain is used instead of Gini impurity for calculating Hoeffding bounds.</li><li><font class="code">input_model</font> <font class="codetype">(mlpack.HoeffdingTreeModelType)</font>: Input trained Hoeffding tree model.</li><li><font class="code">labels</font> <font class="codetype">(numpy vector or array, int/long dtype)</font>: Labels for training dataset.</li><li><font class="code">max_samples</font> <font class="codetype">(int)</font>: Maximum number of samples before splitting.  Default value 5000.</li><li><font class="code">min_samples</font> <font class="codetype">(int)</font>: Minimum number of samples before splitting.  Default value 100.</li><li><font class="code">numeric_split_strategy</font> <font class="codetype">(string)</font>: The splitting strategy to use for numeric features: 'domingos' or 'binary'.  Default value binary.</li><li><font class="code">observations_before_binning</font> <font class="codetype">(int)</font>: If the 'domingos' split strategy is used, this specifies the number of samples observed before binning is performed.  Default value 100.</li><li><font class="code">passes</font> <font class="codetype">(int)</font>: Number of passes to take over the dataset.  Default value 1.</li><li><font class="code">test</font> <font class="codetype">(mlpack.TUPLE_TYPEType)</font>: Testing dataset (may be categorical).</li><li><font class="code">test_labels</font> <font class="codetype">(numpy vector or array, int/long dtype)</font>: Labels of test data.</li><li><font class="code">training</font> <font class="codetype">(mlpack.TUPLE_TYPEType)</font>: Training dataset (may be categorical).</li><li><font class="code">verbose</font> <font class="codetype">(bool)</font>: Display informational messages and the full list of parameters and timers at the end of execution.</li></ul>
<h2>output options</h2>
<p>The return value from the binding is a dict containing the following elements:</p>
<ul><li><font class="code">output_model</font> <font class="codetype">(mlpack.HoeffdingTreeModelType)</font>: Output for trained Hoeffding tree model.</li><li><font class="code">predictions</font> <font class="codetype">(numpy vector, int dtype)</font>: Matrix to output label predictions for test data into.</li><li><font class="code">probabilities</font> <font class="codetype">(numpy matrix, float dtype)</font>: In addition to predicting labels, provide rediction probabilities in this matrix.</li><ul>
</ul>
</div>
</body>
</html>
