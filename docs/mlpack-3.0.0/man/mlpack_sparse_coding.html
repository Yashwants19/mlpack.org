<html >
<head >

<meta name="keywords" content="mlpack, libmlpack, c++, armadillo, machine learning, data mining, classification, regression, tree-based methods, dual-tree algorithm">
<meta name="description" content="mlpack: a scalable c++ machine learning library">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title >mlpack: a scalable c++ machine learning library</title>
</head><link rel="stylesheet" href="../../../style.css" /></link><link rel="stylesheet" href="../../style-man.css" /></link><link href="http://fonts.googleapis.com/css?family=Maven+Pro:500" rel="stylesheet" type="text/css" /></link>



<body ><br /></br>


<div class="titlebar">
   <a href="http://www.mlpack.org"><img src="../../../mlpack.png"></a>
</div>
<center >
<div class="mlnavbar">
  <div class="navcontainer">
   <div class="mlnavitem" name="mlnavmain"><a href="../../../index.html">main</a></div>
   <div class="mlnavitem" name="mlnavabout"><a href="../../../about.html">about</a></div>
   <div class="mlnavitem" name="mlnavdoc"><a href="../../../docs.html">docs</a></div>
   <div class="mlnavitem" name="mlnavhelp"><a href="../../../help.html">get help</a></div>
   <div class="mlnavitem" name="mlnavbugs"><a href="https://github.com/mlpack/mlpack">github</a></div>
  </div>
</div>
</center>
<div class="separator"></div>
<center >
<div class="mainsection smallertext manpage">

<h1 align="center">mlpack_sparse_coding</h1>



<h2>NAME
<a name="NAME"></a>
</h2>



<p class="closemargin first"><font class="code">mlpack_sparse_coding</font>
- sparse coding</p>

<h2>SYNOPSIS
<a name="SYNOPSIS"></a>
</h2>



<p class="closemargin first"><font class="code">mlpack_sparse_coding</font>
[<font class="code">-h</font>] [<font class="code">-v</font>]</p>

<h2>DESCRIPTION
<a name="DESCRIPTION"></a>
</h2>


<p class="closemargin first">An
implementation of Sparse Coding with Dictionary Learning,
which achieves sparsity via an l1-norm regularizer on the
codes (LASSO) or an (l1+l2)<font class="code">-norm</font> regularizer on the
codes (the Elastic Net). Given a dense data matrix X with d
dimensions and n points, sparse coding seeks to find a dense
dictionary matrix D with k atoms in d dimensions, and a
sparse coding matrix Z with n points in k dimensions.</p>

<p class="closemargin first">The original
data matrix X can then be reconstructed as Z * D. Therefore,
this program finds a representation of each point in X as a
sparse linear combination of atoms in the dictionary D.</p>

<p class="closemargin first">The sparse
coding is found with an algorithm which alternates between a
dictionary step, which updates the dictionary D, and a
sparse coding step, which updates the sparse coding
matrix.</p>

<p class="closemargin first">Once a
dictionary D is found, the sparse coding model may be used
to encode other matrices, and saved for future usage.</p>

<p class="closemargin first">To run this
program, either an input matrix or an already-saved sparse
coding model must be specified. An input matrix may be
specified with the &rsquo;<font class="code">--training_file</font>
(<font class="code">-t</font>)&rsquo; option, along with the number of atoms in
the dictionary (specified with the &rsquo;<font class="code">--atoms</font>
(<font class="code">-k</font>)&rsquo; parameter). It is also possible to
specify an initial dictionary for the optimization, with the
&rsquo;<font class="code">--initial_dictionary_file</font> (<font class="code">-i</font>)&rsquo;
parameter. An input model may be specified with the
&rsquo;<font class="code">--input_model_file</font> (<font class="code">-m</font>)&rsquo;
parameter.</p>

<p class="closemargin first">As an example,
to build a sparse coding model on the dataset
&rsquo;data.csv&rsquo; using 200 atoms and an
l1-regularization parameter of 0.1, saving the model into
&rsquo;model.bin&rsquo;, use</p>

<p class="closemargin first">$ sparse_coding
<font class="code">--training_file</font> data.csv <font class="code">--atoms</font> 200
<font class="code">--lambda1</font> 0.1 <font class="code">--output_model_file</font>
model.bin</p>

<p class="closemargin first">Then, this
model could be used to encode a new matrix,
&rsquo;otherdata.csv&rsquo;, and save the output codes to
&rsquo;codes.csv&rsquo;:</p>

<p class="closemargin first">$ sparse_coding
<font class="code">--input_model_file</font> model.bin <font class="code">--test_file</font>
otherdata.csv <font class="code">--codes_file</font> codes.csv</p>

<h2>OPTIONAL INPUT OPTIONS
<a name="OPTIONAL INPUT OPTIONS"></a>
</h2>


<p class="closemargin first"><font class="code">--atoms (-k)
[int]</font></p>

<p class="farmargin">Number of atoms in the
dictionary. Default value 15.</p>

<p class="closemargin"><font class="code">--help (-h) [bool]</font></p>

<p class="farmargin">Default help info.</p>

<p class="closemargin"><font class="code">--info [string]</font></p>

<p class="farmargin">Get help on a specific module
or option. Default value &rsquo;&rsquo;.
<font class="code">--initial_dictionary_file</font> (<font class="code">-i</font>) [string]
Optional initial dictionary matrix. Default value
&rsquo;&rsquo;. <font class="code">--input_model_file</font> (<font class="code">-m</font>)
[unknown] File containing input sparse coding model. Default
value &rsquo;&rsquo;.</p>

<p class="closemargin"><font class="code">--lambda1 (-l)
[double]</font></p>

<p class="farmargin">Sparse coding l1-norm
regularization parameter. Default value 0.</p>

<p class="closemargin"><font class="code">--lambda2 (-L)
[double]</font></p>

<p class="farmargin">Sparse coding l2-norm
regularization parameter. Default value 0.</p>

<p class="closemargin"><font class="code">--max_iterations (-n)
[int]</font></p>

<p class="farmargin">Maximum number of iterations
for sparse coding (0 indicates no limit). Default value 0.
<font class="code">--newton_tolerance</font> (<font class="code">-w</font>) [double] Tolerance for
convergence of Newton method. Default value 1e-06.</p>

<p class="closemargin"><font class="code">--normalize (-N)
[bool]</font></p>

<p class="farmargin">If set, the input data matrix
will be normalized before coding.
<font class="code">--objective_tolerance</font> (<font class="code">-o</font>) [double] Tolerance
for convergence of the objective function. Default value
0.01.</p>

<p class="closemargin"><font class="code">--seed (-s) [int]</font></p>

<p class="farmargin">Random seed. If 0,
&rsquo;std::time(NULL)&rsquo; is used. Default value 0.</p>

<p class="closemargin"><font class="code">--test_file (-T)
[string]</font></p>

<p class="farmargin">Optional matrix to be encoded
by trained model. Default value &rsquo;&rsquo;.
<font class="code">--training_file</font> (<font class="code">-t</font>) [string] Matrix of
training data (X). Default value &rsquo;&rsquo;.</p>

<p class="closemargin"><font class="code">--verbose (-v)
[bool]</font></p>

<p class="farmargin">Display informational messages
and the full list of parameters and timers at the end of
execution.</p>

<p class="closemargin"><font class="code">--version (-V)
[bool]</font></p>

<p class="farmargin">Display the version of
mlpack.</p>

<h2>OPTIONAL OUTPUT OPTIONS
<a name="OPTIONAL OUTPUT OPTIONS"></a>
</h2>



<p class="closemargin first"><font class="code">--codes_file
(-c) [string]</font></p>

<p class="farmargin">Matrix to save the output
sparse codes of the test matrix (<font class="code">--test_file</font>) to.
Default value &rsquo;&rsquo;. <font class="code">--dictionary_file</font>
(<font class="code">-d</font>) [string] Matrix to save the output dictionary
to. Default value &rsquo;&rsquo;. <font class="code">--output_model_file</font>
(<font class="code">-M</font>) [unknown] File to save trained sparse coding
model to. Default value &rsquo;&rsquo;.</p>

<h2>ADDITIONAL INFORMATION
<a name="ADDITIONAL INFORMATION"></a>
</h2>


<h2>ADDITIONAL INFORMATION
<a name="ADDITIONAL INFORMATION"></a>
</h2>


<p class="closemargin first">For further
information, including relevant papers, citations, and
theory, For further information, including relevant papers,
citations, and theory, consult the documentation found at
http://www.mlpack.org or included with your consult the
documentation found at http://www.mlpack.org or included
with your DISTRIBUTION OF MLPACK. DISTRIBUTION OF
MLPACK.</p>
</div></body></html>
